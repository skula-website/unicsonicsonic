#!/usr/bin/env python3
"""
Enhanced Fingerprint Analysis Script
Analyzes audio files for AI watermarks using multiple detection methods:
- Energy ratio analysis (18-22 kHz vs 14-18 kHz)
- Phase coherence analysis (detects phase randomization)
- Spectral normalization detection (detects artificial ratio reduction)
- High-frequency noise analysis (detects dithering)
- Filter artifact detection (detects multi-stage filtering)
"""

import sys
import json
import numpy as np
import librosa
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import matplotlib.pyplot as plt
from scipy import signal

def analyze_fingerprint(input_path, output_path=None, skip_image=False):
    """
    Enhanced analysis of audio file for AI watermarks.
    
    Args:
        input_path: Path to input audio file
        output_path: Optional path for spectrogram image
        skip_image: If True, skip image generation
    """
    try:
        # Load audio file
        print(f"Loading audio: {input_path}")
        y, sr = librosa.load(input_path, sr=None)
        duration = len(y) / sr
        nyquist_freq = sr / 2
        
        print(f"Sample rate: {sr} Hz, Duration: {duration:.2f}s, Nyquist: {nyquist_freq:.1f} Hz")
        
        # Use higher resolution STFT for phase analysis
        n_fft = 2048  # Higher resolution for phase analysis
        hop_length = 512
        stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
        
        # Define frequency ranges
        watermark_min = 18000
        watermark_max = 22000
        reference_min = 14000
        reference_max = 18000
        high_freq_min = 15000  # For filter artifact detection
        high_freq_max = 17000
        
        # Find frequency indices
        watermark_idx = (frequencies >= watermark_min) & (frequencies <= watermark_max)
        reference_idx = (frequencies >= reference_min) & (frequencies <= reference_max)
        high_freq_idx = (frequencies >= high_freq_min) & (frequencies <= high_freq_max)
        
        # ===== 1. ENERGY RATIO ANALYSIS (Original method) =====
        watermark_energy = np.mean(magnitude[watermark_idx, :]) if np.any(watermark_idx) else 0
        reference_energy = np.mean(magnitude[reference_idx, :]) if np.any(reference_idx) else 0
        energy_ratio = watermark_energy / reference_energy if reference_energy > 0 else 0
        
        # Frame-by-frame ratios
        watermark_frames = magnitude[watermark_idx, :] if np.any(watermark_idx) else np.zeros((0, magnitude.shape[1]))
        reference_frames = magnitude[reference_idx, :] if np.any(reference_idx) else np.zeros((0, magnitude.shape[1]))
        
        frame_ratios = []
        for i in range(watermark_frames.shape[1]):
            wm_energy = np.mean(watermark_frames[:, i]) if watermark_frames.shape[0] > 0 else 0
            ref_energy = np.mean(reference_frames[:, i]) if reference_frames.shape[0] > 0 and reference_frames.shape[1] > i else 0
            if ref_energy > 0:
                frame_ratios.append(wm_energy / ref_energy)
        
        frame_ratios = np.array(frame_ratios)
        
        # Statistics
        mean_frame_ratio = np.mean(frame_ratios) if len(frame_ratios) > 0 else 0
        median_frame_ratio = np.median(frame_ratios) if len(frame_ratios) > 0 else 0
        max_frame_ratio = np.max(frame_ratios) if len(frame_ratios) > 0 else 0
        watermark_to_reference_ratio = energy_ratio
        median_watermark_to_reference = median_frame_ratio
        
        # Frame percentages
        baseline_ratio = 0.18  # Clean audio baseline
        very_low_threshold = 0.10
        elevated_threshold = 0.25
        higher_threshold = 0.35
        suspicious_threshold = 0.5
        
        frames_above_very_low = np.sum(frame_ratios > very_low_threshold) / len(frame_ratios) * 100 if len(frame_ratios) > 0 else 0
        frames_above_baseline = np.sum(frame_ratios > baseline_ratio) / len(frame_ratios) * 100 if len(frame_ratios) > 0 else 0
        frames_watermark_higher = np.sum(frame_ratios > higher_threshold) / len(frame_ratios) * 100 if len(frame_ratios) > 0 else 0
        frames_watermark_elevated = np.sum(frame_ratios > elevated_threshold) / len(frame_ratios) * 100 if len(frame_ratios) > 0 else 0
        suspicious_frames = np.sum(frame_ratios > suspicious_threshold) / len(frame_ratios) * 100 if len(frame_ratios) > 0 else 0
        
        # ===== 2. PHASE COHERENCE ANALYSIS (Detects phase randomization) =====
        # Watermark frequencies should have consistent phase patterns if watermarked
        # Random phase indicates removal attempt
        if np.any(watermark_idx):
            watermark_phase = phase[watermark_idx, :]
            # Calculate phase variance (high variance = randomized phase)
            phase_variance = np.var(watermark_phase, axis=0)  # Variance across frequencies per frame
            mean_phase_variance = np.mean(phase_variance)
            
            # Calculate phase coherence (how consistent phase is across time)
            # Low coherence = randomized phase (removal attempt)
            phase_coherence = 1.0 / (1.0 + mean_phase_variance)  # Normalized to 0-1
            
            # Reference phase for comparison
            if np.any(reference_idx):
                reference_phase = phase[reference_idx, :]
                ref_phase_variance = np.var(reference_phase, axis=0)
                mean_ref_phase_variance = np.mean(ref_phase_variance)
                ref_phase_coherence = 1.0 / (1.0 + mean_ref_phase_variance)
                
                # If watermark phase is much less coherent than reference, likely randomized
                phase_coherence_ratio = phase_coherence / ref_phase_coherence if ref_phase_coherence > 0 else 1.0
            else:
                phase_coherence_ratio = 1.0
        else:
            mean_phase_variance = 0
            phase_coherence = 1.0
            phase_coherence_ratio = 1.0
        
        # ===== 3. SPECTRAL NORMALIZATION DETECTION =====
        # Remover targets ratio ~0.15 (below natural baseline of 0.18)
        # If ratio is suspiciously close to 0.15, might be normalized
        normalization_suspicion = 0.0
        if energy_ratio > 0:
            # Check if ratio is artificially low (between 0.12-0.18 suggests normalization)
            if 0.12 <= energy_ratio <= 0.18:
                # Calculate how close to target (0.15)
                distance_from_target = abs(energy_ratio - 0.15)
                # Closer to 0.15 = more suspicious
                normalization_suspicion = 1.0 - (distance_from_target / 0.06)  # Max suspicion at 0.15
            elif energy_ratio < 0.12:
                # Very low ratio might indicate aggressive filtering
                normalization_suspicion = 0.8
        
        # ===== 4. HIGH-FREQUENCY NOISE ANALYSIS (Detects dithering) =====
        # Check for pink noise characteristics in high frequencies (14-22 kHz)
        # Pink noise has 1/f power spectrum
        noise_analysis_range = (frequencies >= 14000) & (frequencies <= 22000)
        if np.any(noise_analysis_range):
            high_freq_magnitude = magnitude[noise_analysis_range, :]
            # Calculate power spectrum slope
            # Pink noise should have approximately -3 dB/octave slope
            freq_subset = frequencies[noise_analysis_range]
            # Remove DC and very low frequencies
            valid_freqs = freq_subset[freq_subset > 0]
            if len(valid_freqs) > 1:
                # Calculate average power per frequency bin
                avg_power = np.mean(high_freq_magnitude, axis=1)
                # Fit linear regression to log-log plot (power vs frequency)
                log_freqs = np.log10(valid_freqs)
                log_power = np.log10(avg_power[:len(valid_freqs)] + 1e-10)  # Avoid log(0)
                
                if len(log_freqs) > 1:
                    # Simple slope calculation
                    slope = np.polyfit(log_freqs, log_power, 1)[0]
                    # Pink noise slope is approximately -1 (in log-log space)
                    # White noise slope is 0
                    # If slope is close to -1, might be pink noise (dithering)
                    pink_noise_indicator = abs(slope + 1.0)  # Closer to 0 = more pink noise-like
                    dithering_suspicion = max(0, 1.0 - pink_noise_indicator * 2)  # Scale to 0-1
                else:
                    dithering_suspicion = 0.0
            else:
                dithering_suspicion = 0.0
        else:
            dithering_suspicion = 0.0
        
        # ===== 5. FILTER ARTIFACT DETECTION =====
        # Multi-stage filtering (17 kHz â†’ 15.5 kHz) creates specific artifacts
        # Check for sharp cutoffs in frequency response
        if np.any(high_freq_idx):
            # Calculate energy drop-off around 15.5-17 kHz
            energy_below_15k = np.mean(magnitude[frequencies < 15000, :]) if np.any(frequencies < 15000) else 0
            energy_15_17k = np.mean(magnitude[high_freq_idx, :]) if np.any(high_freq_idx) else 0
            energy_above_17k = np.mean(magnitude[(frequencies > 17000) & (frequencies < 18000), :]) if np.any((frequencies > 17000) & (frequencies < 18000)) else 0
            
            if energy_below_15k > 0:
                # Check for sharp drop-off (sign of aggressive filtering)
                dropoff_15_17 = energy_15_17k / energy_below_15k if energy_below_15k > 0 else 0
                dropoff_17_18 = energy_above_17k / energy_below_15k if energy_below_15k > 0 else 0
                
                # Sharp drop-off suggests multi-stage filtering
                if dropoff_15_17 < 0.3 and dropoff_17_18 < 0.1:
                    filter_artifact_suspicion = 0.8
                elif dropoff_15_17 < 0.5:
                    filter_artifact_suspicion = 0.5
                else:
                    filter_artifact_suspicion = 0.0
            else:
                filter_artifact_suspicion = 0.0
        else:
            filter_artifact_suspicion = 0.0
        
        # ===== 6. MFCC ANALYSIS (External analyzers check this) =====
        # MFCCs represent spectral content, pitch, and timbre
        # AI-generated audio may have characteristic MFCC patterns
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=hop_length)
        mfcc_mean = np.mean(mfcc, axis=1)
        mfcc_std = np.std(mfcc, axis=1)
        
        # Calculate MFCC variance (AI audio may have lower variance)
        mfcc_variance = np.var(mfcc)
        # Normalize to 0-1 (lower variance = more suspicious)
        mfcc_suspicion = max(0, 1.0 - (mfcc_variance / 10.0))  # Threshold at 10.0
        
        # ===== 7. CHROMA FEATURES ANALYSIS =====
        # Chroma represents harmonic structure (12 pitch classes)
        chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)
        chroma_mean = np.mean(chroma, axis=1)
        chroma_std = np.std(chroma, axis=1)
        
        # AI audio may have more uniform chroma distribution
        chroma_uniformity = np.std(chroma_mean)  # Lower std = more uniform = more suspicious
        chroma_suspicion = max(0, 1.0 - (chroma_uniformity / 0.1))  # Threshold at 0.1
        
        # ===== 8. SPECTRAL CONTRAST ANALYSIS =====
        # Measures difference in amplitude between frequency bands
        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=hop_length)
        contrast_mean = np.mean(spectral_contrast)
        contrast_std = np.std(spectral_contrast)
        
        # AI audio may have unnatural contrast patterns
        # Very low or very high contrast can be suspicious
        contrast_suspicion = 0.0
        if contrast_mean < 5.0 or contrast_mean > 20.0:
            contrast_suspicion = 0.5
        if contrast_std < 2.0:  # Too consistent
            contrast_suspicion = max(contrast_suspicion, 0.3)
        
        # ===== 9. PITCH AND RHYTHM ANALYSIS =====
        # Analyze pitch contours and rhythmic patterns
        pitches, magnitudes = librosa.piptrack(y=y, sr=sr, hop_length=hop_length)
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0
        pitch_std = np.std(pitches[pitches > 0]) if np.any(pitches > 0) else 0
        
        # AI audio may have too-regular pitch patterns
        pitch_regularity = 1.0 / (1.0 + pitch_std) if pitch_std > 0 else 1.0
        pitch_suspicion = max(0, pitch_regularity - 0.5) * 2  # Scale to 0-1
        
        # Rhythm analysis: detect tempo and regularity
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr, hop_length=hop_length)
        # Very regular tempo can be suspicious
        tempo_suspicion = 0.0
        if tempo > 0:
            # Check if tempo is suspiciously round (e.g., exactly 120 BPM)
            # Convert to float to avoid numpy scalar issues
            tempo_float = float(tempo)
            tempo_roundness = abs(tempo_float - round(tempo_float))
            if tempo_roundness < 0.5:  # Very close to round number
                tempo_suspicion = 0.2
        
        # ===== 10. SPECTRAL CENTROID AND BANDWIDTH ANALYSIS =====
        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length)[0]
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr, hop_length=hop_length)[0]
        
        centroid_mean = np.mean(spectral_centroid)
        centroid_std = np.std(spectral_centroid)
        bandwidth_mean = np.mean(spectral_bandwidth)
        bandwidth_std = np.std(spectral_bandwidth)
        
        # AI audio may have unnatural centroid/bandwidth patterns
        # Very consistent values can be suspicious
        centroid_suspicion = max(0, 1.0 - (centroid_std / 500.0))  # Threshold at 500 Hz
        bandwidth_suspicion = max(0, 1.0 - (bandwidth_std / 1000.0))  # Threshold at 1000 Hz
        
        # ===== 11. COMBINED DETECTION SCORE (Enhanced) =====
        # Weight different detection methods
        energy_score = 1.0 if energy_ratio > 0.35 else (0.5 if energy_ratio > 0.25 else 0.0)
        phase_score = 1.0 - phase_coherence_ratio  # Low coherence = removal attempt
        normalization_score = normalization_suspicion
        dithering_score = dithering_suspicion
        filter_score = filter_artifact_suspicion
        
        # New feature scores
        mfcc_score = mfcc_suspicion
        chroma_score = chroma_suspicion
        contrast_score = contrast_suspicion
        pitch_score = pitch_suspicion + tempo_suspicion
        spectral_score = (centroid_suspicion + bandwidth_suspicion) / 2
        
        # Combined suspicion score (0-1) - updated weights
        combined_suspicion = (
            energy_score * 0.25 +      # Energy ratio (reduced weight)
            phase_score * 0.15 +        # Phase randomization
            normalization_score * 0.10 +  # Spectral normalization
            dithering_score * 0.10 +    # Dithering
            filter_score * 0.08 +      # Filter artifacts
            mfcc_score * 0.12 +         # MFCC patterns (NEW)
            chroma_score * 0.08 +      # Chroma features (NEW)
            contrast_score * 0.05 +    # Spectral contrast (NEW)
            pitch_score * 0.05 +       # Pitch/rhythm (NEW)
            spectral_score * 0.04      # Spectral centroid/bandwidth (NEW)
        )
        
        # ===== 7. DETERMINE STATUS =====
        # Enhanced status determination
        # IMPROVED: Recognize clean zone (0.12-0.18) as "clean" even with some high frames
        # This is our target range for files with suspicious energy that need fixing
        
        # Check if ratio is in clean zone (our target range)
        # IMPROVED: Extended to 0.11-0.18 to account for slight variations
        in_clean_zone = 0.11 <= energy_ratio <= 0.18
        
        if energy_ratio > 0.35:
            # Very high ratio - definitely watermarked
            status = "watermarked"
        elif energy_ratio > 0.25 or (frames_watermark_elevated > 10 and not in_clean_zone):
            # High ratio or many elevated frames (but not in clean zone)
            status = "suspicious"
        elif frames_watermark_higher > 15 and not in_clean_zone:
            # Many high frames, but only if NOT in clean zone
            # (In clean zone, some high frames are OK - we're fixing outliers)
            status = "watermarked"
        elif frames_watermark_higher > 18 and in_clean_zone:
            # In clean zone, but too many high frames (>18%) - still suspicious
            status = "suspicious"
        elif in_clean_zone:
            # Ratio in clean zone (0.12-0.18) - this is our target!
            # Even if there are some high frames or normalization suspicion,
            # this is considered "clean" because we're fixing suspicious energy
            if max_frame_ratio > 10.0 or mean_frame_ratio > 0.5:
                # Still has significant outliers - might need more processing
                status = "suspicious"
            elif frames_watermark_higher > 18:
                # Too many high frames even in clean zone
                status = "suspicious"
            else:
                # Clean zone achieved with reasonable frame distribution
                # Allow up to 18% high frames (increased from 15%) when in clean zone
                status = "clean"
        elif combined_suspicion > 0.6 and energy_ratio < 0.12:
            # High suspicion from removal techniques, and very low ratio
            status = "possibly_cleaned"
        elif energy_ratio < 0.12:
            # Very low ratio suggests aggressive filtering
            status = "possibly_cleaned"
        elif 0.12 <= energy_ratio <= 0.18:
            # This should be caught by in_clean_zone above, but fallback
            status = "clean"
        else:
            # Default to clean for ratios between 0.18 and 0.25
            status = "clean"
        
        # Prepare result
        result = {
            "sampleRate": int(sr),
            "duration": round(float(duration), 2),
            "nyquistFreq": round(float(nyquist_freq), 1),
            # Energy metrics
            "watermarkEnergy": round(float(watermark_energy), 6),
            "energyRatio": round(float(energy_ratio), 4),
            "meanFrameRatio": round(float(mean_frame_ratio), 4),
            "medianFrameRatio": round(float(median_frame_ratio), 4),
            "maxFrameRatio": round(float(max_frame_ratio), 4),
            "watermarkToReferenceRatio": round(float(watermark_to_reference_ratio), 4),
            "medianWatermarkToReference": round(float(median_watermark_to_reference), 4),
            "framesWatermarkHigherPercent": round(float(frames_watermark_higher), 2),
            "framesWatermarkElevatedPercent": round(float(frames_watermark_elevated), 2),
            "framesAboveVeryLowPercent": round(float(frames_above_very_low), 2),
            "framesAboveBaselinePercent": round(float(frames_above_baseline), 2),
            "suspiciousFramesPercent": round(float(suspicious_frames), 2),
            # Enhanced detection metrics
            "phaseCoherence": round(float(phase_coherence), 4),
            "phaseCoherenceRatio": round(float(phase_coherence_ratio), 4),
            "normalizationSuspicion": round(float(normalization_suspicion), 4),
            "ditheringSuspicion": round(float(dithering_suspicion), 4),
            "filterArtifactSuspicion": round(float(filter_artifact_suspicion), 4),
            # New feature metrics (matching external analyzers)
            "mfccSuspicion": round(float(mfcc_suspicion), 4),
            "chromaSuspicion": round(float(chroma_suspicion), 4),
            "spectralContrastSuspicion": round(float(contrast_suspicion), 4),
            "pitchSuspicion": round(float(pitch_suspicion), 4),
            "tempoSuspicion": round(float(tempo_suspicion), 4),
            "spectralCentroidSuspicion": round(float(centroid_suspicion), 4),
            "spectralBandwidthSuspicion": round(float(bandwidth_suspicion), 4),
            "combinedSuspicion": round(float(combined_suspicion), 4),
            "status": status
        }
        
        # Generate spectrogram if requested
        if not skip_image and output_path:
            try:
                print(f"Generating spectrogram: {output_path}", flush=True)
                fig, ax = plt.subplots(figsize=(8, 4))
                
                # Downsample for faster rendering
                max_time_bins = 300
                if magnitude.shape[1] > max_time_bins:
                    step = magnitude.shape[1] // max_time_bins
                    magnitude_display = magnitude[:, ::step]
                    hop_display = hop_length * step
                else:
                    magnitude_display = magnitude
                    hop_display = hop_length
                
                img = librosa.display.specshow(
                    librosa.amplitude_to_db(magnitude_display, ref=np.max),
                    y_axis='hz',
                    x_axis='time',
                    sr=sr,
                    hop_length=hop_display,
                    ax=ax,
                    cmap='viridis'
                )
                
                # Add frequency range markers
                ax.axhline(y=watermark_min, color='r', linestyle='--', linewidth=1.5, label='Watermark (18-22 kHz)')
                ax.axhline(y=watermark_max, color='r', linestyle='--', linewidth=1.5)
                ax.axhline(y=reference_min, color='g', linestyle='--', linewidth=1.5, label='Reference (14-18 kHz)')
                ax.axhline(y=reference_max, color='g', linestyle='--', linewidth=1.5)
                ax.axhline(y=15500, color='orange', linestyle=':', linewidth=1, alpha=0.7, label='Filter cutoff (15.5 kHz)')
                ax.axhline(y=17000, color='orange', linestyle=':', linewidth=1, alpha=0.7, label='Filter cutoff (17 kHz)')
                ax.set_ylim([0, 24000])
                
                # Enhanced status text
                status_text = f"Status: {status.upper()}\nRatio: {watermark_to_reference_ratio:.3f}\nSuspicion: {combined_suspicion:.2f}"
                ax.text(0.02, 0.98, status_text, transform=ax.transAxes, 
                       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='black', alpha=0.6, ec='none'),
                       fontsize=10, fontweight='bold', color='white')
                
                # Colorbar
                cbar = plt.colorbar(img, ax=ax, format='%+2.0f dB')
                cbar.ax.yaxis.set_tick_params(color='white')
                cbar.ax.yaxis.label.set_color('white')
                plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color='white')
                
                ax.set_title('Enhanced Audio Spectrogram - Watermark Analysis', fontsize=12, fontweight='bold', color='white')
                ax.set_xlabel('Time', color='white')
                ax.set_ylabel('Frequency (Hz)', color='white')
                ax.tick_params(axis='x', colors='white')
                ax.tick_params(axis='y', colors='white')
                ax.spines['bottom'].set_color('white')
                ax.spines['top'].set_color('white')
                ax.spines['left'].set_color('white')
                ax.spines['right'].set_color('white')
                
                ax.legend(loc='upper right', fontsize=8, framealpha=0.7, facecolor='black', edgecolor='white', labelcolor='white')
                plt.tight_layout()
                
                plt.savefig(output_path, dpi=60, bbox_inches='tight', facecolor='#1e293b')
                plt.close(fig)
                print(f"Spectrogram saved: {output_path}", flush=True)
            except Exception as e:
                print(f"Warning: Could not generate spectrogram: {e}", file=sys.stderr, flush=True)
        
        # Print JSON result
        print(json.dumps(result), flush=True)
        return result
        
    except Exception as e:
        error_msg = f"Analysis error: {str(e)}"
        print(error_msg, file=sys.stderr)
        result = {"success": False, "error": error_msg}
        print(json.dumps(result))
        return result

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(json.dumps({"success": False, "error": "Usage: analyze_fingerprint.py <input> [output_image] [--json]"}))
        sys.exit(1)
    
    input_path = sys.argv[1]
    
    has_json_flag = '--json' in sys.argv
    
    output_path = None
    for arg in sys.argv[2:]:
        if arg != '--json' and not arg.startswith('-'):
            output_path = arg
            break
    
    skip_image = (output_path is None)
    
    result = analyze_fingerprint(input_path, output_path, skip_image)
    sys.exit(0 if "error" not in result else 1)
